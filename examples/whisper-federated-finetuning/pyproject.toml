[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "whisper_example"
version = "1.0.0"
description = "On-device Federated Finetuning for Speech Classification"
license = "Apache-2.0"
dependencies = [
    "flwr[simulation]>=1.11.0",
    "flwr-datasets[audio]>=0.3.0",
    "transformers==4.44.2",
    "torch==2.4.1",
]

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.flwr.app]
publisher = "flwrlabs"

[tool.flwr.app.components]
serverapp = "whisper_example.server_app:app"
clientapp = "whisper_example.client_app:app"

[tool.flwr.app.config]
num-server-rounds = 3
fraction-fit = 0.01 # sample 1% of clients in each round (1% of 2112 is 21)
num-classes = 12
batch-size = 8
compile-model = false
disable-tqdm = true

[tool.flwr.federations]
default = "local-sim"


[tool.flwr.federations.local-sim]
options.num-supernodes = 2112 # number unique speakers in training partition
options.backend.client-resources.num-cpus = 4
options.backend.client-resources.num-gpus = 0.0

[tool.flwr.federations.local-sim-gpu]
options.num-supernodes = 2112 # number unique speakers in training partition
options.backend.client-resources.num-cpus = 4
options.backend.client-resources.num-gpus = 0.5
